{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataSet:\n",
    "    \n",
    "    def __init__(self, word):\n",
    "        self.chars2idx = {}\n",
    "        self.indexs  = []\n",
    "        for c in word: \n",
    "            if c not in self.chars2idx:\n",
    "                self.chars2idx[c] = len(self.chars2idx)\n",
    "                \n",
    "            self.indexs.append(self.chars2idx[c])\n",
    "            \n",
    "        self.vec_size = len(self.chars2idx)\n",
    "        self.seq_len  = len(word)\n",
    "        \n",
    "    def get_one_hot(self, idx):\n",
    "        x = torch.zeros(self.vec_size)\n",
    "        x[idx] = 1\n",
    "        return x\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return zip(self.indexs[:-1], self.indexs[1:])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.seq_len\n",
    "    \n",
    "    def get_char_by_id(self, id):\n",
    "        for c, i in self.chars2idx.items():\n",
    "            if id == i: return c\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тестовое слово\n",
    "word = 'ololoasdasddqweqw123456789'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, in_size = 5, hidden_size = 3, out_size = 5):\n",
    "        super(LSTM, self).__init__() \n",
    "        #input gate\n",
    "        self.hidden_ii   = nn.Linear(in_features = in_size, out_features = hidden_size)\n",
    "        self.hidden_hi   = nn.Linear(in_features = hidden_size, out_features = hidden_size)\n",
    "        # forget gate\n",
    "        self.hidden_if   = nn.Linear(in_features = in_size, out_features = hidden_size)\n",
    "        self.hidden_hf   = nn.Linear(in_features = hidden_size, out_features = hidden_size)\n",
    "        # gate gate\n",
    "        self.hidden_ig   = nn.Linear(in_features = in_size, out_features = hidden_size)\n",
    "        self.hidden_hg   = nn.Linear(in_features = hidden_size, out_features = hidden_size)\n",
    "        # output gate\n",
    "        self.hidden_io   = nn.Linear(in_features = in_size, out_features = hidden_size)\n",
    "        self.hidden_ho   = nn.Linear(in_features = hidden_size, out_features = hidden_size)\n",
    "        # activations\n",
    "        self.tanh        = nn.Tanh()\n",
    "        self.sigmoid     = nn.Sigmoid()\n",
    "        # out\n",
    "        self.out         = nn.Linear(in_features = hidden_size, out_features = out_size)\n",
    "    \n",
    "    def forward(self, x, prev_c, prev_h):\n",
    "        i = self.sigmoid(self.hidden_ii(x) + self.hidden_hi(prev_h))\n",
    "        f = self.sigmoid(self.hidden_if(x) + self.hidden_hf(prev_h))\n",
    "        g = self.tanh(self.hidden_ig(x) + self.hidden_hg(prev_h))\n",
    "        o = self.sigmoid(self.hidden_io(x) + self.hidden_ho(prev_h))\n",
    "        c = f * prev_c + i * g\n",
    "        h = o * self.tanh(c)\n",
    "        return self.out(h), c, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация переменных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds        = WordDataSet(word = word)\n",
    "lstm      = LSTM(in_size = ds.vec_size, hidden_size = 10, out_size = ds.vec_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "e_cnt     = 100\n",
    "optim     = SGD(lstm.parameters(), lr = 0.1, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.697265625\n",
      "Clip gradient :  2.691818253015925\n",
      "65.51197814941406\n",
      "Clip gradient :  3.04446056192994\n",
      "41.48557662963867\n",
      "Clip gradient :  6.498533868747408\n",
      "27.55721664428711\n",
      "Clip gradient :  8.200489264492742\n",
      "20.307024002075195\n",
      "Clip gradient :  8.618617800689991\n",
      "14.103322982788086\n",
      "Clip gradient :  16.021302304462274\n",
      "9.740650177001953\n",
      "Clip gradient :  15.963398406759852\n",
      "4.4009318351745605\n",
      "Clip gradient :  2.7400219023757737\n",
      "0.9384341239929199\n",
      "Clip gradient :  0.5041099492626817\n",
      "0.2759885787963867\n",
      "Clip gradient :  0.1785601245306558\n"
     ]
    }
   ],
   "source": [
    "CLIP_GRAD = True\n",
    "\n",
    "for epoch in range(e_cnt):\n",
    "    hh = torch.zeros(lstm.hidden_hi.in_features)\n",
    "    cc = torch.zeros(lstm.hidden_hi.in_features)\n",
    "    loss = 0\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    for sample, next_sample in ds:\n",
    "        x = ds.get_one_hot(sample).unsqueeze(0)\n",
    "        target = torch.LongTensor([next_sample])\n",
    "        y, cc, hh = lstm(x, cc, hh)   \n",
    "        loss += criterion(y, target)\n",
    "     \n",
    "    loss.backward()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print (loss.data.item())\n",
    "        if CLIP_GRAD: print(\"Clip gradient : \", torch.nn.utils.clip_grad_norm_(lstm.parameters(), max_norm = 5))\n",
    "    else: \n",
    "        if CLIP_GRAD: torch.nn.utils.clip_grad_norm_(lstm.parameters(), max_norm = 1)\n",
    "    \n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\t ololoasdasddqweqw123456789\n",
      "Original:\t ololoasdasddqweqw123456789\n"
     ]
    }
   ],
   "source": [
    "lstm.eval()\n",
    "hh = torch.zeros(lstm.hidden_hi.in_features)\n",
    "cc = torch.zeros(lstm.hidden_hi.in_features)\n",
    "id = 0\n",
    "softmax  = nn.Softmax(dim=1)\n",
    "predword = ds.get_char_by_id(id)\n",
    "for c in enumerate(word[:-1]):\n",
    "    x = ds.get_one_hot(id).unsqueeze(0)\n",
    "    y, cc, hh = lstm(x, cc, hh)\n",
    "    y = softmax(y)\n",
    "    m, id = torch.max(y, 1)\n",
    "    id = id.data[0]\n",
    "    predword += ds.get_char_by_id(id)\n",
    "print ('Prediction:\\t' , predword)\n",
    "print(\"Original:\\t\", word)\n",
    "assert(predword == word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, in_size = 5, hidden_size = 3, out_size = 5):\n",
    "        super(GRU, self).__init__() \n",
    "        #update gate\n",
    "        self.hidden_iu   = nn.Linear(in_features = in_size, out_features = hidden_size)\n",
    "        self.hidden_hu   = nn.Linear(in_features = hidden_size, out_features = hidden_size)\n",
    "        # reset gate\n",
    "        self.hidden_ir   = nn.Linear(in_features = in_size, out_features = hidden_size)\n",
    "        self.hidden_hr   = nn.Linear(in_features = hidden_size, out_features = hidden_size)\n",
    "        # hidde_cell gate\n",
    "        self.hidden_ihc   = nn.Linear(in_features = in_size, out_features = hidden_size)\n",
    "        self.hidden_hhc   = nn.Linear(in_features = hidden_size, out_features = hidden_size)\n",
    "        # activations\n",
    "        self.tanh        = nn.Tanh()\n",
    "        self.sigmoid     = nn.Sigmoid()\n",
    "        # out\n",
    "        self.out         = nn.Linear(in_features = hidden_size, out_features = out_size)\n",
    "    \n",
    "    def forward(self, x, prev_h):\n",
    "        u = self.sigmoid(self.hidden_iu(x) + self.hidden_hu(prev_h))\n",
    "        r = self.sigmoid(self.hidden_ir(x) + self.hidden_hr(prev_h))\n",
    "        hc = self.tanh(self.hidden_ihc(x) + self.hidden_hhc(r * prev_h))\n",
    "        h = (1 - u) * hc + u * prev_h\n",
    "        return self.out(h), h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация переменных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds        = WordDataSet(word = word)\n",
    "gru       = GRU(in_size = ds.vec_size, hidden_size = 15, out_size = ds.vec_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "e_cnt     = 100\n",
    "optim     = SGD(gru.parameters(), lr = 0.1, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.8460922241211\n",
      "Clip gradient :  4.4838711183361575\n",
      "52.6328125\n",
      "Clip gradient :  9.973733043087073\n",
      "27.040254592895508\n",
      "Clip gradient :  9.989557519635085\n",
      "12.121700286865234\n",
      "Clip gradient :  4.136827103818908\n",
      "3.3191709518432617\n",
      "Clip gradient :  3.5985249242969495\n",
      "0.8404607772827148\n",
      "Clip gradient :  1.9510484040243632\n",
      "0.18989944458007812\n",
      "Clip gradient :  0.40503203241825914\n",
      "0.07626724243164062\n",
      "Clip gradient :  0.0950081273625977\n",
      "0.04526805877685547\n",
      "Clip gradient :  0.0384570612505573\n",
      "0.03318595886230469\n",
      "Clip gradient :  0.023802809413985673\n"
     ]
    }
   ],
   "source": [
    "CLIP_GRAD = True\n",
    "\n",
    "for epoch in range(e_cnt):\n",
    "    hh = torch.zeros(gru.hidden_hu.in_features)\n",
    "\n",
    "    loss = 0\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    for sample, next_sample in ds:\n",
    "        x = ds.get_one_hot(sample).unsqueeze(0)\n",
    "        target = torch.LongTensor([next_sample])\n",
    "        y, hh = gru(x, hh)   \n",
    "        loss += criterion(y, target)\n",
    "     \n",
    "    loss.backward()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print (loss.data.item())\n",
    "        if CLIP_GRAD: print(\"Clip gradient : \", torch.nn.utils.clip_grad_norm_(gru.parameters(), max_norm = 5))\n",
    "    else: \n",
    "        if CLIP_GRAD: torch.nn.utils.clip_grad_norm_(gru.parameters(), max_norm = 1)\n",
    "    \n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\t ololoasdasddqweqw123456789\n",
      "Original:\t ololoasdasddqweqw123456789\n"
     ]
    }
   ],
   "source": [
    "gru.eval()\n",
    "hh = torch.zeros(gru.hidden_hu.in_features)\n",
    "id = 0\n",
    "softmax  = nn.Softmax(dim=1)\n",
    "predword = ds.get_char_by_id(id)\n",
    "for c in enumerate(word[:-1]):\n",
    "    x = ds.get_one_hot(id).unsqueeze(0)\n",
    "    y, hh = gru(x, hh)\n",
    "    y = softmax(y)\n",
    "    m, id = torch.max(y, 1)\n",
    "    id = id.data[0]\n",
    "    predword += ds.get_char_by_id(id)\n",
    "print ('Prediction:\\t' , predword)\n",
    "print(\"Original:\\t\", word)\n",
    "assert(predword == word)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
