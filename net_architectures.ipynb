{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import random\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_ID = 1\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Для запуска без GPU раскомментировать и закоментировать код выше\n",
    "# DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100500)\n",
    "\n",
    "def data2image(data):\n",
    "    res = np.transpose(np.reshape(data ,(3, 32,32)), (1,2,0))\n",
    "    return PIL.Image.fromarray(np.uint8(res))\n",
    "\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor): img = img.numpy().astype('uint8')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "def prediction2classes(output_var):\n",
    "    _, predicted = torch.max(output_var.data, 1)\n",
    "    predicted.squeeze_()\n",
    "    classes = predicted.tolist()\n",
    "    return classes\n",
    "\n",
    "def make_solution_pytorch(net, input_tensor, a_batch_size):\n",
    "    res = []\n",
    "    net = net.eval()\n",
    "    cur_pos = 0\n",
    "    while cur_pos <= len(input_tensor):\n",
    "        outputs = net(input_tensor[cur_pos:cur_pos+a_batch_size])\n",
    "        res += prediction2classes(outputs)\n",
    "        cur_pos += a_batch_size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, input_path, is_train=True, transform=None):\n",
    "                        \n",
    "        data = np.load(input_path)\n",
    "        if is_train: \n",
    "            self.Y, self.X = np.hsplit(data, [1]) \n",
    "            self.Y = [item[0] for item in self.Y]\n",
    "        else: \n",
    "            self.X = data\n",
    "            self.Y = None\n",
    "            \n",
    "        self.X = self.X.reshape((self.X.shape[0], 3, 32, 32))\n",
    "        self.X = self.X.transpose((0, 2, 3, 1)) #приводим к виду (N, H, W, C)\n",
    "        self.X = [Image.fromarray(img) for img in self.X]\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.X[idx]\n",
    "\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "\n",
    "        if self.Y is None: return sample\n",
    "        else: return (sample, self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH  = '/home/azamat.sultanov/hw4/'\n",
    "train_path = 'homework_4.train.npy'\n",
    "test_path  = 'homework_4_no_classes.test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mean = np.mean([item[0].numpy() for item in CifarDataset(DATA_PATH + train_path, transform=transforms.ToTensor())], axis=(0,2,3))\n",
    "np_std = np.std([item[0].numpy() for item in CifarDataset(DATA_PATH + train_path, transform=transforms.ToTensor())], axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform_norm = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")\n",
    "\n",
    "cifar_test_transform_norm = transforms.Compose([    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = CifarDataset(DATA_PATH + train_path, transform=cifar_transform_norm)\n",
    "dataloader_train_norm = DataLoader(dataset_train_norm, batch_size=128,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_test_norm = CifarDataset(DATA_PATH + test_path, is_train=False, transform=cifar_test_transform_norm)\n",
    "dataloader_test_norm = DataLoader(dataset_test_norm, batch_size=128,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "def train_network(a_net, \n",
    "                  a_device,\n",
    "                  dataloader_train_norm=dataloader_train_norm,\n",
    "                  a_epochs=80,\n",
    "                  a_batch_size=128,\n",
    "                  a_lr=0.1):\n",
    "    \n",
    "    train_acc = []\n",
    "    net = a_net.to(a_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(a_epochs)):  # loop over the dataset multiple times\n",
    "        if epoch == 42:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/10, weight_decay=0.0001, momentum=0.9) \n",
    "        elif epoch == 65:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/100, weight_decay=0.0001, momentum=0.9) \n",
    "        \n",
    "        net = net.train()        \n",
    "        epoch_accuracy = 0.0\n",
    "        epoch_iters = 0\n",
    "        for item in dataloader_train_norm:\n",
    "            \n",
    "            epoch_iters += 1\n",
    "\n",
    "            inputs = item[0].to(a_device)\n",
    "            labels = item[1].long().to(a_device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_accuracy += accuracy_score(labels, prediction2classes(outputs))\n",
    "\n",
    "        epoch_accuracy /= epoch_iters\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        \n",
    "        print(\"Epoch \", epoch, round(train_acc[-1], 4))\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    plt.plot(train_acc, label='Train')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StupidDenseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StupidDenseNet, self).__init__()\n",
    "        \n",
    "        self.classifier = nn.Sequential()\n",
    "        self.classifier.add_module('lin1', nn.Linear(3*32*32, 500))\n",
    "        self.classifier.add_module('sig1', torch.nn.Sigmoid())\n",
    "        self.classifier.add_module('lin2', nn.Linear(3*32*32, 500))\n",
    "        self.classifier.add_module('sig2', torch.nn.Sigmoid())\n",
    "        self.classifier.add_module('lin3', nn.Linear(3*32*32, 500))\n",
    "        self.classifier.add_module('sig3', torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        #Увеличиваем кол-во выходных слоев с 84 - до 84*2 - потому что классов 100\n",
    "        self.fc2 = nn.Linear(120, 84*2)\n",
    "        self.fc3 = nn.Linear(84*2, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def conv3x3(a_in_planes, a_out_planes, a_stride=1):\n",
    "        return nn.Conv2d(a_in_planes, a_out_planes,  stride=a_stride,\n",
    "                         kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def x_downsample(a_in_channels, coef):\n",
    "         return nn.Conv2d(a_in_channels, \n",
    "                   a_in_channels*coef,\n",
    "                   kernel_size=1,\n",
    "                   stride=coef,\n",
    "                   bias=False)\n",
    "\n",
    "    def bn(a_out_channels):\n",
    "        return nn.BatchNorm2d(a_out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResidualBlock(nn.Module):\n",
    "    def __init__(self, a_in_channels, make_downsample=False, use_skip_connection=True, DOWNSAMPLE_COEF = 2):\n",
    "        super(CifarResidualBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        self.make_downsample = make_downsample\n",
    "        \n",
    "        if make_downsample: coef = DOWNSAMPLE_COEF\n",
    "        else: coef = 1  \n",
    "            \n",
    "        # сохранение исходных данных\n",
    "        self.coef = coef\n",
    "        self.a_in_channels = a_in_channels\n",
    "        self.a_out_channels = a_in_channels * self.coef\n",
    "        \n",
    "        # создание слоя для сэмплинга\n",
    "        if self.make_downsample:\n",
    "            self.downsample = x_downsample(self.a_in_channels, self.coef)\n",
    "            \n",
    "        # создание конволюционных и батчнорм слоев\n",
    "        self.conv1 = conv3x3(self.a_in_channels, self.a_out_channels, a_stride = self.coef)\n",
    "        self.bn1 = bn(self.a_out_channels)\n",
    "        \n",
    "        self.conv2 = conv3x3(self.a_out_channels, self.a_out_channels)\n",
    "        self.bn2 = bn(self.a_out_channels)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        residual_x = x\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        \n",
    "        if self.use_skip_connection:\n",
    "            if self.make_downsample:\n",
    "                residual_x = self.downsample(residual_x)\n",
    "            x += residual_x\n",
    "            \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CifarResNet, self).__init__()\n",
    "                \n",
    "        self.features = nn.Sequential()\n",
    "        \n",
    "        self.global_conv3x3 =  conv3x3(3,32)\n",
    "        \n",
    "        self.features.add_module('res_block1', CifarResidualBlock(32))\n",
    "        self.features.add_module('res_block2', CifarResidualBlock(32))\n",
    "        self.features.add_module('res_block3', CifarResidualBlock(32, make_downsample = True))\n",
    "        \n",
    "        self.features.add_module('res_block4', CifarResidualBlock(64))\n",
    "        self.features.add_module('res_block5', CifarResidualBlock(64))\n",
    "        self.features.add_module('res_block6', CifarResidualBlock(64))\n",
    "        self.features.add_module('res_block7', CifarResidualBlock(64, make_downsample = True))\n",
    "        \n",
    "        self.features.add_module('res_block8', CifarResidualBlock(128))\n",
    "        self.features.add_module('res_block9', CifarResidualBlock(128))\n",
    "        self.features.add_module('res_block10', CifarResidualBlock(128))\n",
    "        self.features.add_module('res_block11', CifarResidualBlock(128, make_downsample = True))\n",
    "        \n",
    "        self.features.add_module('res_block12', CifarResidualBlock(256))\n",
    "        self.features.add_module('res_block13', CifarResidualBlock(256))\n",
    "        self.features.add_module('res_block14', CifarResidualBlock(256))\n",
    "        self.features.add_module('res_block15', CifarResidualBlock(256, make_downsample = True))\n",
    "        \n",
    "        \n",
    "        self.global_avg_pooling = nn.AvgPool2d(kernel_size=2)\n",
    "        self.fc_classifier = nn.Linear(512, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.global_conv3x3(x)\n",
    "        x = self.features(x)\n",
    "        x = self.global_avg_pooling(x) \n",
    "        x = x.view((x.size()[0], -1))        \n",
    "        x = self.fc_classifier(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_net = StupidDenseNet()\n",
    "# %time train_network(dense_net, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet = LeNet()\n",
    "# %time train_network(lenet, torch.device('cpu'), a_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet = LeNet()\n",
    "# %time train_network(lenet, torch.device(DEVICE), a_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet = LeNet()\n",
    "# %time train_network(lenet, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e13340e0fae42b49a9b49a47649109a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 0.0813\n",
      "Epoch  1 0.1692\n",
      "Epoch  2 0.2338\n",
      "Epoch  3 0.2906\n",
      "Epoch  4 0.3409\n",
      "Epoch  5 0.3879\n",
      "Epoch  6 0.4254\n",
      "Epoch  7 0.4629\n",
      "Epoch  8 0.4929\n",
      "Epoch  9 0.5197\n",
      "Epoch  10 0.5415\n",
      "Epoch  11 0.5635\n",
      "Epoch  12 0.5797\n",
      "Epoch  13 0.5977\n",
      "Epoch  14 0.6131\n",
      "Epoch  15 0.6285\n",
      "Epoch  16 0.6453\n",
      "Epoch  17 0.6541\n",
      "Epoch  18 0.6632\n",
      "Epoch  19 0.6806\n",
      "Epoch  20 0.687\n",
      "Epoch  21 0.6976\n",
      "Epoch  22 0.7042\n",
      "Epoch  23 0.7185\n",
      "Epoch  24 0.7265\n",
      "Epoch  25 0.732\n",
      "Epoch  26 0.7402\n",
      "Epoch  27 0.7495\n",
      "Epoch  28 0.7562\n",
      "Epoch  29 0.7614\n",
      "Epoch  30 0.7719\n",
      "Epoch  31 0.7732\n",
      "Epoch  32 0.7807\n",
      "Epoch  33 0.7836\n",
      "Epoch  34 0.7953\n",
      "Epoch  35 0.8044\n",
      "Epoch  36 0.804\n",
      "Epoch  37 0.8073\n",
      "Epoch  38 0.8161\n",
      "Epoch  39 0.8193\n",
      "Epoch  40 0.8204\n",
      "Epoch  41 0.8236\n",
      "Epoch  42 0.9172\n",
      "Epoch  43 0.9478\n",
      "Epoch  44 0.9572\n",
      "Epoch  45 0.9627\n",
      "Epoch  46 0.9685\n",
      "Epoch  47 0.9719\n",
      "Epoch  48 0.975\n",
      "Epoch  49 0.9772\n",
      "Epoch  50 0.9785\n",
      "Epoch  51 0.9809\n",
      "Epoch  52 0.9822\n",
      "Epoch  53 0.9848\n",
      "Epoch  54 0.9863\n",
      "Epoch  55 0.9862\n",
      "Epoch  56 0.9866\n",
      "Epoch  57 0.9889\n",
      "Epoch  58 0.9887\n",
      "Epoch  59 0.9902\n",
      "Epoch  60 0.9903\n",
      "Epoch  61 0.991\n",
      "Epoch  62 0.9913\n",
      "Epoch  63 0.9922\n",
      "Epoch  64 0.9929\n",
      "Epoch  65 0.9929\n",
      "Epoch  66 0.9934\n",
      "Epoch  67 0.9937\n",
      "Epoch  68 0.994\n",
      "Epoch  69 0.9944\n",
      "Epoch  70 0.9938\n",
      "Epoch  71 0.9946\n",
      "Epoch  72 0.9948\n",
      "Epoch  73 0.9948\n",
      "Epoch  74 0.995\n",
      "Epoch  75 0.9943\n",
      "Epoch  76 0.9944\n",
      "Epoch  77 0.995\n",
      "Epoch  78 0.9953\n",
      "Epoch  79 0.9954\n",
      "\n",
      "Finished Training\n",
      "CPU times: user 1h 12min 34s, sys: 27min 4s, total: 1h 39min 38s\n",
      "Wall time: 1h 40min 39s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet = CifarResNet()\n",
    "%time train_network(resnet, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_solution(a_net, a_device):\n",
    "    res = []\n",
    "    net = a_net.eval()\n",
    "    for item in dataloader_test_norm:\n",
    "        inputs = item.to(a_device)\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        res += prediction2classes(outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solution = make_solution(resnet, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_solution.csv', 'w') as fout:\n",
    "    print('Id', 'Prediction', sep=',', file=fout)\n",
    "    for i, prediction in enumerate(my_solution):\n",
    "        print(i, prediction, sep=',', file=fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
